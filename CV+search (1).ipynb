{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest - Harris County 2017 Foreclosure Sale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Looping through GridSearchCV, Cross-validation and PCA for tuning paramenters, model selection and feature selection\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Step: 1) Data loading and cleaning\n",
    "- Step: 2) Formatting for machine learning \n",
    "- Step: 3) Cross validation and modeling \n",
    "- Step: 4) Test/evaluate \n",
    "- Step: 5) Repeate Step: 2-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "path1 = (\"C:/Users/aath/Dropbox/MAEN/Thankful/Data/fls/FLS_Hist2017_clean.csv\")\n",
    "df = pd.read_csv(path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec_num                  0\n",
       "keymap                1022\n",
       "sold3rd                  0\n",
       "tax_id                 439\n",
       "org_loan_amt           361\n",
       "mon_org_loan_date      277\n",
       "year_org_loan_date     279\n",
       "sale_date                0\n",
       "est_loan_bal           857\n",
       "mortgagee               28\n",
       "bedr_num              1286\n",
       "prop_val               506\n",
       "Term                  1005\n",
       "Trustee                  1\n",
       "sq_ft                  614\n",
       "time_sold             3591\n",
       "trustee_ref_num       4762\n",
       "open_bid              4359\n",
       "final_bid             3605\n",
       "loan_type               43\n",
       "dtype: int64"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check null status of the columns\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Eliminate few rows with nulls \n",
    "df = df[pd.notnull(df['Trustee'])]\n",
    "df = df[pd.notnull(df['mortgagee'])]\n",
    "df = df[pd.notnull(df['loan_type'])]\n",
    "df = df.drop('rec_num', 1)   # This is an arbitrary index and should be removed\n",
    "\n",
    "# This is the actual sales dates in 2017. This is time-series which we will ignore here\n",
    "df = df.drop('sale_date', 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop all other columns with many nulls\n",
    "df=df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_df = df.drop('sold3rd', 1)\n",
    "labels_df = df['sold3rd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mortgagee\n",
      "854\n",
      "Trustee\n",
      "300\n",
      "loan_type\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# Check to see how many unique categories we may need to create\n",
    "categorical = features_df.select_dtypes(include=['object'])\n",
    "for i in categorical:\n",
    "    column = categorical[i]\n",
    "    print(i)\n",
    "    print(column.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mortgagee' 'Trustee' 'loan_type']\n"
     ]
    }
   ],
   "source": [
    "# Set up feature transforming functions\n",
    "\n",
    "def transform_feature( features_df, column_name ):\n",
    "    unique_values = set( features_df[column_name].tolist() )\n",
    "    transformer_dict = {}\n",
    "    for ii, value in enumerate(unique_values):\n",
    "        transformer_dict[value] = ii\n",
    "\n",
    "    def label_map(y):\n",
    "        return transformer_dict[y]\n",
    "    features_df[column_name] = features_df[column_name].apply( label_map )\n",
    "    return features_df\n",
    "\n",
    "\n",
    "# transformation\n",
    "\n",
    "names_of_columns_to_transform = [\"mortgagee\", \"Trustee\",\"loan_type\"]\n",
    "for column in names_of_columns_to_transform:\n",
    "    features_features_df = transform_feature(features_df, column )\n",
    "\n",
    "print(features_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5043"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores [ 0.86206897  0.8625818   0.8625    ]\n",
      "Decision Tree Scores [ 0.80796671  0.80844735  0.78869048]\n",
      "Random Forest Scores [ 0.81747919  0.80844735  0.81309524]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.linear_model\n",
    "import sklearn.cross_validation\n",
    "import sklearn.tree\n",
    "import sklearn.ensemble\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print(\"Logistic Regression Scores {}\".format(score))\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print(\"Decision Tree Scores {}\".format(score))\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print(\"Random Forest Scores {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.preprocessing\n",
    "\n",
    "def hot_encoder(df, column_name):\n",
    "    column = df[column_name].tolist()\n",
    "    column = np.reshape( column, (len(column), 1) )  ### needs to be an N x 1 numpy array\n",
    "    enc = sklearn.preprocessing.OneHotEncoder()\n",
    "    enc.fit( column )\n",
    "    new_column = enc.transform( column ).toarray()\n",
    "    column_titles = []\n",
    "    ### making titles for the new columns, and appending them to dataframe\n",
    "    for ii in range( len(new_column[0]) ):\n",
    "        this_column_name = column_name+\"_\"+str(ii)\n",
    "        df[this_column_name] = new_column[:,ii]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mortgagee' 'Trustee' 'loan_type']\n"
     ]
    }
   ],
   "source": [
    "print(features_df.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Scores [ 0.86206897  0.8625818   0.8625    ]\n",
      "Decision Tree Scores [ 0.80915577  0.80963712  0.78511905]\n",
      "Random Forest Scores [ 0.81331748  0.82331945  0.83452381]\n"
     ]
    }
   ],
   "source": [
    "X = features_df.as_matrix()\n",
    "y = labels_df.tolist()\n",
    "\n",
    "clf = sklearn.linear_model.LogisticRegression()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print(\"Logistic Regression Scores {}\".format(score))\n",
    "\n",
    "clf = sklearn.tree.DecisionTreeClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print(\"Decision Tree Scores {}\".format(score))\n",
    "\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "score = sklearn.cross_validation.cross_val_score( clf, X, y )\n",
    "print(\"Random Forest Scores {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we tested three different calssifiers and all of them preform very similar to each others. However, all of these algorithsm have adjustable variables and we just used the default ones. \n",
    "\n",
    "Let's focus on the Random Forest model and see if we can fine tune its parameters to get better results. We can eaither manually adust them or use GridSearchCV tool. This tool will exhaustively search over specificed parameter value and reprot the best ones. However, we should do this search using our best features. And for that we can use SelectKBest tool helping to rank features based on lowest p-values.\n",
    "\n",
    "You may realize that there are many moving parts in this workflow and yet another tool that can help to combine these together is pipeline package. Pipeline chains the transformation step of SelectKBest with the estimation step of RandomForestClassifier into a coherent workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91      1431\n",
      "          1       0.22      0.06      0.09       234\n",
      "\n",
      "avg / total       0.77      0.84      0.80      1665\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn.pipeline\n",
    "\n",
    "select = sklearn.feature_selection.SelectKBest(k='all')\n",
    "clf = sklearn.ensemble.RandomForestClassifier()\n",
    "\n",
    "steps = [('feature_selection', select),\n",
    "         ('random_forest', clf)]\n",
    "\n",
    "pipeline = sklearn.pipeline.Pipeline(steps)\n",
    "\n",
    "X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# fit pipeline on X_train and y_train\n",
    "pipeline.fit( X_train, y_train )\n",
    "\n",
    "# call pipeline.predict() on X_test data to make a set of test predictions\n",
    "y_prediction = pipeline.predict( X_test )\n",
    "\n",
    "# test predictions using sklearn.classification_report()\n",
    "report = sklearn.metrics.classification_report( y_test, y_prediction )\n",
    "\n",
    "# and print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature_selection': SelectKBest(k='all', score_func=<function f_classif at 0x000000000CB9A048>), 'random_forest': RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      1.00      0.92      1431\n",
      "          1       0.00      0.00      0.00       234\n",
      "\n",
      "avg / total       0.74      0.86      0.79      1665\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aath\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.grid_search\n",
    "\n",
    "k_range = [i+1 for i in range(3)]         # Number of features selected\n",
    "n_range = [i+1 for i in range(20)]        # The number of trees in the forest\n",
    "split_range = [i+2 for i in range(3)]     # The minimum number of samples required to split a node\n",
    "\n",
    "parameters = dict(feature_selection__k=k_range,  \n",
    "              random_forest__n_estimators=n_range,\n",
    "              random_forest__min_samples_split= split_range)\n",
    "\n",
    "cv = sklearn.grid_search.GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "print(pipeline.named_steps)\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "y_predictions = cv.predict(X_test)\n",
    "\n",
    "report = sklearn.metrics.classification_report( y_test, y_predictions )\n",
    "\n",
    "# and print the report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
